{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from tqdm import tqdm\n",
    "from GeoConformalizedExplainer import GeoConformalizedExplainer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Basic Functions",
   "id": "7a9112e6c56ff389"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.rcParams['legend.fontsize'] = 16\n",
    "\n",
    "\n",
    "def plot_s(b, k=3, size=50, filename=None, sub_titles=None, non_spatial=None, vmin=None, vmax=None, interpolation=None,\n",
    "           cmap=plt.get_cmap('viridis', 36)):\n",
    "    fig, axes = plt.subplots(1, k, figsize=(6 * k, 5), dpi=500)\n",
    "\n",
    "    for i in range(k):\n",
    "        ax = axes[i]\n",
    "        if i in non_spatial:\n",
    "            ax.scatter(b[i][0], b[i][1], s=5, color='black')\n",
    "            ax.set_ylim(b[i][2], b[i][3])\n",
    "            ax.set_xlim(-2.5, 2.5)\n",
    "            ax.set_xlabel(r'$X_{}$'.format(i), fontsize=16)\n",
    "            ax.xaxis.set_tick_params(labelsize=20)\n",
    "            ax.yaxis.set_tick_params(labelsize=20)\n",
    "            ax.grid(False)\n",
    "        else:\n",
    "            if vmin is None:\n",
    "                v_min = np.floor(b[i].min() * 10) / 10\n",
    "            else:\n",
    "                v_min = vmin\n",
    "            if vmax is None:\n",
    "                v_max = np.ceil(b[i].max() * 10) / 10\n",
    "            else:\n",
    "                v_max = vmax\n",
    "            c = ax.imshow(b[i].reshape(size, size), cmap=cmap, vmin=v_min, vmax=v_max, interpolation=interpolation)\n",
    "            cb = fig.colorbar(c, ax=ax)\n",
    "            cb.ax.tick_params(labelsize=20)\n",
    "            ax.set_xticks(np.arange(-0.5, size, 5))\n",
    "            ax.set_yticks(np.arange(-0.5, size, 5))\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_axis_off()\n",
    "            ax.tick_params(axis='x', colors=(0, 0, 0, 0))\n",
    "            ax.tick_params(axis='y', colors=(0, 0, 0, 0))\n",
    "        ax.set_title(sub_titles[i], fontsize=20, y=1.05)\n",
    "\n",
    "    plt.savefig(filename, bbox_inches='tight')\n",
    "\n"
   ],
   "id": "9dfc903061de8ad3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_uncertainty(u, k=3, filename=None, sub_titles=None, cmap='flare', s_limits=(5, 20), hue='geo_uncertainty',\n",
    "                     size='shap_abs'):\n",
    "    fig, axes = plt.subplots(1, k, figsize=(6 * k, 5), dpi=500)\n",
    "    sns.set_style(\"white\")\n",
    "\n",
    "    for i in range(k):\n",
    "        ax = axes[i]\n",
    "        data = u[i]\n",
    "        g = sns.scatterplot(data=data, x='x', y='y', hue=hue, size=size, palette=cmap, sizes=s_limits, legend=False,\n",
    "                            edgecolor='.7', ax=ax)\n",
    "        g.set(xlabel='', ylabel='', aspect='equal')\n",
    "        ax.set_title(sub_titles[i], fontsize=20, y=1.05)\n",
    "\n",
    "    plt.savefig(filename, bbox_inches='tight')"
   ],
   "id": "7350c1600e73e37c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_coverage(c, k=3, size=50, filename=None, sub_titles=None, colors=None, cmap=None):\n",
    "    fig, axes = plt.subplots(1, k, figsize=(6 * k, 5), dpi=500)\n",
    "    legend_elements = [Patch(facecolor=colors[0], edgecolor='.7', label='Not Covered'),\n",
    "                       Patch(facecolor=colors[1], edgecolor='.7', label='Covered')]\n",
    "    for i in range(k):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(c[i].reshape(size, size), cmap=cmap, vmin=0, vmax=1)\n",
    "        ax.legend(handles=legend_elements, loc='upper right', title='')\n",
    "        ax.set_title(sub_titles[i], fontsize=20, y=1.05)\n",
    "    plt.savefig(filename, bbox_inches='tight')"
   ],
   "id": "e2b353d3e98d272b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def noise_2d_generation(noise_level):\n",
    "  print(noise_level)\n",
    "\n",
    " # noise_level=100\n",
    "\n",
    "  x = np.linspace(-2, 2, 50)\n",
    "  y = np.linspace(-2, 2, 50)\n",
    "  X, Y = np.meshgrid(x, y)\n",
    "  pos = np.dstack((X, Y))\n",
    "  mean = [1, 1]\n",
    "  covariance = [[2, 1], [1, 2]]\n",
    "  rv = multivariate_normal(mean, covariance)\n",
    "  n1 = rv.pdf(pos) * noise_level\n",
    "  n1 = n1 - n1.mean()\n",
    "\n",
    "  # Plot the distribution\n",
    "  plt.contourf(X, Y, n1, levels=20, cmap='coolwarm')\n",
    "  plt.colorbar(label='Density')\n",
    "  plt.title('2D Distribution with Positive and Negative Values')\n",
    "  plt.xlabel('X')\n",
    "  plt.ylabel('Y')\n",
    "  plt.show()\n",
    "\n",
    "  gaussians = [\n",
    "      multivariate_normal([3, 3], [[2, 0], [0, 2]]).pdf(pos),\n",
    "      multivariate_normal([-3, -3], [[3, 1], [1, 3]]).pdf(pos),\n",
    "      multivariate_normal([0, 0], [[4, 0], [0, 4]]).pdf(pos)\n",
    "  ]\n",
    "\n",
    "  n2 = (gaussians[0] - gaussians[1] + gaussians[2]) * noise_level\n",
    "  n2 = n2 - n2.mean()\n",
    "\n",
    "  # Plot the distribution\n",
    "  plt.contourf(X, Y, n2, levels=20, cmap='coolwarm')\n",
    "  plt.colorbar(label='value')\n",
    "  plt.title('2D Distribution with Positive and Negative Values')\n",
    "  plt.xlabel('X')\n",
    "  plt.ylabel('Y')\n",
    "  plt.show()\n",
    "\n",
    "  sigma = 1.2\n",
    "  Z1 = np.exp(-((Y - X) ** 2) / (2 * sigma ** 2))\n",
    "  Z2 = np.exp(-((Y - (2 - X)) ** 2) / (2 * sigma ** 2))\n",
    "  Z = Z1 + Z2\n",
    "\n",
    "  Z_min, Z_max = Z.min(), Z.max()\n",
    "  n3 = 0.05 * (Z - Z_min) / (Z_max - Z_min) * noise_level\n",
    "\n",
    "  plt.contourf(X, Y, n3, levels=20, cmap='coolwarm')\n",
    "  plt.colorbar(label='value')\n",
    "  plt.title('2D Distribution with Positive and Negative Values')\n",
    "  plt.xlabel('X')\n",
    "  plt.ylabel('Y')\n",
    "  plt.show()\n",
    "\n",
    "  return n1, n2, n3"
   ],
   "id": "86aed789ecd5734a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "noise_2d_generation(20)",
   "id": "4b39e24e4f3f3a14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def noise_uniform_generation(noise_level):\n",
    "    n1 = np.random.uniform(-0.05, 0.05, size=(50, 50)) * noise_level\n",
    "    n2 = np.random.uniform(-0.05, 0.05, size=(50, 50)) * noise_level\n",
    "    n3 = np.random.uniform(-0.05, 0.05, size=(50, 50)) * noise_level\n",
    "    return n1, n2, n3"
   ],
   "id": "ea2f1bc6f368ff90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def noise_2d_constant_generation(noise_level):\n",
    "    x = np.linspace(-2, 2, 50)\n",
    "    y = np.linspace(-2, 2, 50)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    pos = np.dstack((X, Y))\n",
    "    mean = [1, 1]\n",
    "    covariance = [[2, 1], [1, 2]]\n",
    "    rv = multivariate_normal(mean, covariance)\n",
    "    n = rv.pdf(pos) * noise_level\n",
    "    n = n - n.mean()\n",
    "    return n"
   ],
   "id": "ba3476b2f2beb1a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def noise_uniform_constant_generation(noise_level):\n",
    "    return np.random.uniform(-0.05, 0.05, size=(50, 50)) * noise_level"
   ],
   "id": "97661d5794e118c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "def Eva(noise_level, cached_results=None, option=0, noise_type='gaussian'):\n",
    "    size = 50\n",
    "\n",
    "    # 生成噪声数据\n",
    "    # 系数噪声 & 常数项噪声\n",
    "    if noise_type == 'gaussian':\n",
    "        n1, n2, n3 = noise_2d_generation(noise_level)\n",
    "        constant_noise =  noise_2d_constant_generation(noise_level)\n",
    "    elif noise_type == 'uniform':\n",
    "        n1, n2, n3 = noise_uniform_generation(noise_level)\n",
    "        constant_noise = noise_uniform_constant_generation(noise_level)\n",
    "\n",
    "    current_combination = f'{noise_type}_X1_only'\n",
    "    if option == 0:\n",
    "        current_combination = f'{noise_type}_X1_only'\n",
    "        n2 = np.zeros((size, size))\n",
    "        n3 = np.zeros((size, size))\n",
    "        constant_noise = np.zeros((size, size))\n",
    "    elif option == 1:\n",
    "        current_combination = f'{noise_type}_X2_only'\n",
    "        n1 = np.zeros((size, size))\n",
    "        n3 = np.zeros((size, size))\n",
    "        constant_noise = np.zeros((size, size))\n",
    "    elif option == 2:\n",
    "        current_combination = f'{noise_type}_X3_only'\n",
    "        n1 = np.zeros((size, size))\n",
    "        n2 = np.zeros((size, size))\n",
    "        constant_noise = np.zeros((size, size))\n",
    "    elif option == 3:\n",
    "        current_combination = f'{noise_type}_X1_and_X2_and_X3'\n",
    "        constant_noise = np.zeros((size, size))\n",
    "    elif option == 4:\n",
    "        current_combination = f'{noise_type}_X1_and_X2'\n",
    "        n3 = np.zeros((size, size))\n",
    "        constant_noise = np.zeros((size, size))\n",
    "    elif option == 5:\n",
    "        current_combination = f'{noise_type}_X1_and_X3'\n",
    "        n2 = np.zeros((size, size))\n",
    "        constant_noise = np.zeros((size, size))\n",
    "    elif option == 6:\n",
    "        current_combination = f'{noise_type}_X2_and_X3'\n",
    "        n1 = np.zeros((size, size))\n",
    "        constant_noise = np.zeros((size, size))\n",
    "    elif option == 7:\n",
    "        current_combination = f'{noise_type}_constant'\n",
    "        n1 = np.zeros((size, size))\n",
    "        n2 = np.zeros((size, size))\n",
    "        n3 = np.zeros((size, size))\n",
    "\n",
    "    # 生成随机数据\n",
    "    np.random.seed(222)\n",
    "    X1 = np.random.uniform(-2, 2, size * size)\n",
    "    X2 = np.random.uniform(-2, 2, size * size)\n",
    "    X3 = np.random.uniform(-2, 2, size * size)\n",
    "    X4 = np.random.uniform(-2, 2, size * size)\n",
    "    X = np.vstack([X1, X2, X3, X4]).T\n",
    "\n",
    "    # 生成坐标数据\n",
    "    u = np.array([np.linspace(0, size - 1, num=size)] * size).reshape(-1)\n",
    "    v = np.array([np.linspace(0, size - 1, num=size)] * size).T.reshape(-1)\n",
    "    coords = np.array(list(zip(u, v)))\n",
    "\n",
    "    # 构建 DataFrame\n",
    "    X_coords = pd.DataFrame(np.concatenate((X, np.array(coords)), axis=1),\n",
    "                            columns=['X1', 'X2', 'X3', 'X4', 'x_coord', 'y_coord'])\n",
    "\n",
    "    # 划分训练、校准和测试集\n",
    "    loc = X_coords[['x_coord', 'y_coord']]\n",
    "    X_train, X_temp, loc_train, loc_temp = train_test_split(X_coords, loc, train_size=0.8)\n",
    "    X_calib, X_test, loc_calib, loc_test = train_test_split(X_temp, loc_temp, train_size=0.5)\n",
    "\n",
    "    def true_model_predict_with_noise(X_coords):\n",
    "        try:\n",
    "            X_coords = X_coords.values\n",
    "        except:\n",
    "            pass\n",
    "        u = X_coords[:, -1].astype(int)\n",
    "        v = X_coords[:, -2].astype(int)\n",
    "        b_1 = (u + v) / 49 * 3\n",
    "        b_2 = 3 * (np.sin(-2 + 4 / 49 * u) * np.cos(-2 + 4 / 49 * v) + 1)\n",
    "        b_3 = u / 49 * 6\n",
    "        f1 = (b_1 + n1[u, v]) * X_coords[:, 0]\n",
    "        f2 = (b_2 + n2[u, v]) * X_coords[:, 1] ** 2\n",
    "        f3 = (b_3 + n3[u, v]) * X_coords[:, 2] ** 3\n",
    "        y_pred = f1 + f2 + f3 + constant_noise[u, v]\n",
    "        return y_pred\n",
    "\n",
    "    def true_model_predict(X_coords):\n",
    "        try:\n",
    "            X_coords = X_coords.values\n",
    "        except:\n",
    "            pass\n",
    "        u = X_coords[:, -1].astype(int)\n",
    "        v = X_coords[:, -2].astype(int)\n",
    "        b_1 = (u + v) / 49 * 3\n",
    "        b_2 = 3 * (np.sin(-2 + 4 / 49 * u) * np.cos(-2 + 4 / 49 * v) + 1)\n",
    "        b_3 = u / 49 * 6\n",
    "        f1 = b_1 * X_coords[:, 0]\n",
    "        f2 = b_2 * X_coords[:, 1] ** 2\n",
    "        f3 = b_3 * X_coords[:, 2] ** 3\n",
    "        y_pred = f1 + f2 + f3\n",
    "        return y_pred\n",
    "\n",
    "    # # 如果 cached_results 为 None，则计算 results\n",
    "    # if cached_results is None:\n",
    "    #     # 定义 SHAP 值计算函数\n",
    "    #     def shap_value_f(x):\n",
    "    #         explainer_ = shap.Explainer(true_model_predict, x, algorithm='auto')\n",
    "    #         return explainer_(x).values\n",
    "    #\n",
    "    #     # 初始化解释器\n",
    "    #     explainer = GeoConformalizedExplainer(prediction_f=true_model_predict,\n",
    "    #                                           x_train=X_train,\n",
    "    #                                           x_calib=X_calib,\n",
    "    #                                           coord_calib=loc_calib.values,\n",
    "    #                                           miscoverage_level=0.1,\n",
    "    #                                           band_width=25,\n",
    "    #                                           shap_value_f=shap_value_f,\n",
    "    #                                           feature_names=X_calib.columns)\n",
    "    #\n",
    "    #     # 计算 SHAP 值\n",
    "    #     results = explainer.uncertainty_aware_explain(x_test=X_coords, coord_test=loc.values)\n",
    "    #     cached_results = results  # 缓存 results\n",
    "    # else:\n",
    "    #     results = cached_results  # 使用缓存的 results\n",
    "    #\n",
    "    # # 定义带噪声的 SHAP 值计算函数\n",
    "    # # 系数噪声\n",
    "    # def shap_value_f_with_noise(x):\n",
    "    #     explainer_ = shap.Explainer(true_model_predict_with_noise, x, algorithm='auto')\n",
    "    #     return explainer_(x).values\n",
    "    # # 常数项噪声\n",
    "    #\n",
    "    # # 初始化带噪声的解释器\n",
    "    # explainer_with_noise = GeoConformalizedExplainer(prediction_f=true_model_predict_with_noise,\n",
    "    #                                                       x_train=X_train,\n",
    "    #                                                       x_calib=X_calib,\n",
    "    #                                                       coord_calib=loc_calib.values,\n",
    "    #                                                       miscoverage_level=0.1,\n",
    "    #                                                       band_width=25,\n",
    "    #                                                       shap_value_f=shap_value_f_with_noise,\n",
    "    #                                                       feature_names=X_calib.columns)\n",
    "\n",
    "    # lime_explainer = LimeTabularExplainer(X_train.values, feature_names=X_train.columns, verbose=False, mode='regression')\n",
    "    # 如果 cached_results 为 None，则计算 results\n",
    "    if cached_results is None:\n",
    "        # 定义 SHAP 值计算函数\n",
    "        def shap_value_f(x):\n",
    "            explainer_ = shap.Explainer(true_model_predict, x, algorithm='auto')\n",
    "            return explainer_(x).values\n",
    "        # 定义 LIME 计算函数\n",
    "\n",
    "        # def lime_value_f(x):\n",
    "        #     explanations = []\n",
    "        #     for i in range(x.shape[0]):\n",
    "        #         instance = x[i, :]\n",
    "        #         res = lime_explainer.explain_instance(instance, true_model_predict, num_features=len(X_train.columns))\n",
    "        #         explanation = [val[1] for val in res.as_list()]\n",
    "        #         explanations.append(explanation)\n",
    "        #     return np.array(explanations)\n",
    "\n",
    "        # 初始化解释器\n",
    "        explainer = GeoConformalizedExplainer(prediction_f=true_model_predict,\n",
    "                                              x_train=X_train,\n",
    "                                              x_calib=X_calib,\n",
    "                                              coord_calib=loc_calib.values,\n",
    "                                              miscoverage_level=0.1,\n",
    "                                              band_width=25,\n",
    "                                              shap_value_f=shap_value_f,\n",
    "                                              feature_names=X_calib.columns)\n",
    "\n",
    "        # 计算 SHAP 值\n",
    "        results = explainer.uncertainty_aware_explain(x_test=X_coords, coord_test=loc.values)\n",
    "        cached_results = results  # 缓存 results\n",
    "    else:\n",
    "        results = cached_results  # 使用缓存的 results\n",
    "\n",
    "    # 定义带噪声的 SHAP 值计算函数\n",
    "    # 系数噪声\n",
    "    def shap_value_f_with_noise(x):\n",
    "        explainer_ = shap.Explainer(true_model_predict_with_noise, x, algorithm='auto')\n",
    "        return explainer_(x).values\n",
    "    # def lime_value_f_with_noise(x):\n",
    "    #         explanations = []\n",
    "    #         for i in range(x.shape[0]):\n",
    "    #             instance = x[i, :]\n",
    "    #             res = lime_explainer.explain_instance(instance, true_model_predict_with_noise, num_features=len(X_train.columns))\n",
    "    #             explanation = [val[1] for val in res.as_list()]\n",
    "    #             explanations.append(explanation)\n",
    "    #         return np.array(explanations)\n",
    "\n",
    "    # 常数项噪声\n",
    "\n",
    "\n",
    "\n",
    "    # 初始化带噪声的解释器\n",
    "    explainer_with_noise = GeoConformalizedExplainer(prediction_f=true_model_predict_with_noise,\n",
    "                                                          x_train=X_train,\n",
    "                                                          x_calib=X_calib,\n",
    "                                                          coord_calib=loc_calib.values,\n",
    "                                                          miscoverage_level=0.1,\n",
    "                                                          band_width=25,\n",
    "                                                          shap_value_f=shap_value_f_with_noise,\n",
    "                                                          feature_names=X_calib.columns)\n",
    "\n",
    "    # 计算带噪声的 SHAP 值\n",
    "    results_coef_noise = explainer_with_noise.uncertainty_aware_explain(x_test=X_coords, coord_test=loc.values)\n",
    "\n",
    "    # 提取结果\n",
    "    pred_results = results.result_geo\n",
    "    print(pred_results)\n",
    "    pred_results_coef_noise = results_coef_noise.result_geo\n",
    "\n",
    "    # 计算 MSE、RMSE 和 R²\n",
    "    diff_X1 = pred_results_coef_noise.X1_shap - pred_results.X1_shap\n",
    "    mse_X1 = np.mean(diff_X1 ** 2)\n",
    "    rmse_X1 = np.sqrt(mse_X1)\n",
    "    r2_X1 = r2_score(pred_results.X1_shap, pred_results_coef_noise.X1_shap)\n",
    "\n",
    "    diff_X2 = pred_results_coef_noise.X2_shap - pred_results.X2_shap\n",
    "    mse_X2 = np.mean(diff_X2 ** 2)\n",
    "    rmse_X2 = np.sqrt(mse_X2)\n",
    "    r2_X2 = r2_score(pred_results.X2_shap, pred_results_coef_noise.X2_shap)\n",
    "\n",
    "    diff_X3 = pred_results_coef_noise.X3_shap - pred_results.X3_shap\n",
    "    mse_X3 = np.mean(diff_X3 ** 2)\n",
    "    rmse_X3 = np.sqrt(mse_X3)\n",
    "    r2_X3 = r2_score(pred_results.X3_shap, pred_results_coef_noise.X3_shap)\n",
    "\n",
    "    # 计算覆盖率\n",
    "    pred_results_coef_noise['X1_upper_bound_new'] = pred_results_coef_noise['X1_shap'] + pred_results_coef_noise[\n",
    "        'X1_geo_uncertainty']\n",
    "    pred_results_coef_noise['X1_lower_bound_new'] = pred_results_coef_noise['X1_shap'] - pred_results_coef_noise[\n",
    "        'X1_geo_uncertainty']\n",
    "    pred_results_coef_noise['X2_upper_bound_new'] = pred_results_coef_noise['X2_shap'] + pred_results_coef_noise[\n",
    "        'X2_geo_uncertainty']\n",
    "    pred_results_coef_noise['X2_lower_bound_new'] = pred_results_coef_noise['X2_shap'] - pred_results_coef_noise[\n",
    "        'X2_geo_uncertainty']\n",
    "    pred_results_coef_noise['X3_upper_bound_new'] = pred_results_coef_noise['X3_shap'] + pred_results_coef_noise[\n",
    "        'X3_geo_uncertainty']\n",
    "    pred_results_coef_noise['X3_lower_bound_new'] = pred_results_coef_noise['X3_shap'] - pred_results_coef_noise[\n",
    "        'X3_geo_uncertainty']\n",
    "\n",
    "    X1_cover = (pred_results['X1_shap'] <= pred_results_coef_noise['X1_upper_bound_new']) & (\n",
    "            pred_results['X1_shap'] >= pred_results_coef_noise['X1_lower_bound_new'])\n",
    "    X2_cover = (pred_results['X2_shap'] <= pred_results_coef_noise['X2_upper_bound_new']) & (\n",
    "            pred_results['X2_shap'] >= pred_results_coef_noise['X2_lower_bound_new'])\n",
    "    X3_cover = (pred_results['X3_shap'] <= pred_results_coef_noise['X3_upper_bound_new']) & (\n",
    "            pred_results['X3_shap'] >= pred_results_coef_noise['X3_lower_bound_new'])\n",
    "\n",
    "    # result_true_file = f'/content/drive/MyDrive/Research/0-Xiayin_research/2_Conformal SHAP//result_X2_{noise_level}_true.csv'\n",
    "    # pred_results.to_csv(result_true_file)\n",
    "    pred_results.to_csv(f'./results_{noise_type}_nonlinear/results_{noise_level}_true-{current_combination}.csv')\n",
    "\n",
    "    # result_noise_file = f'/content/drive/MyDrive/Research/0-Xiayin_research/2_Conformal SHAP//result_X2_{noise_level}_noise.csv'\n",
    "    # pred_results_coef_noise.to_csv(result_noise_file)\n",
    "    pred_results_coef_noise.to_csv(f'./results_{noise_type}_nonlinear/results_{noise_level}_noise-{current_combination}.csv')\n",
    "\n",
    "    # 计算覆盖率均值\n",
    "    X1_cover_mean = X1_cover.mean()\n",
    "    X2_cover_mean = X2_cover.mean()\n",
    "    X3_cover_mean = X3_cover.mean()\n",
    "\n",
    "    # 输出结果\n",
    "    print(f\"Noise Level: {noise_level}\")\n",
    "    print(\"MSE:\", mse_X1)\n",
    "    print(\"RMSE:\", rmse_X1)\n",
    "    print(\"R²:\", r2_X1)\n",
    "    print(\"X1 Coverage Mean:\", X1_cover_mean)\n",
    "    print(\"X2 Coverage Mean:\", X2_cover_mean)\n",
    "    print(\"X3 Coverage Mean:\", X3_cover_mean)\n",
    "\n",
    "    # 可视化覆盖率\n",
    "    b_cover = [X1_cover.values, X2_cover.values]\n",
    "    sub_titles = [r'$Cover_1$', r'$Cover_2$']\n",
    "    binary_cmap = ListedColormap(['#8ec1da', '#ededed'])\n",
    "    plot_coverage(b_cover, k=2, sub_titles=sub_titles, colors=['#8ec1da', '#ededed'],\n",
    "                  cmap=binary_cmap,\n",
    "                  filename=f'./results_{noise_type}_nonlinear/Coverage-ConformalSHAP+Noise(Level={noise_level})-{current_combination}.pdf')\n",
    "\n",
    "    result = pd.DataFrame({\n",
    "        'noise_level': [noise_level],\n",
    "        'mse_X1': [mse_X1],\n",
    "        'rmse_X1': [rmse_X1],\n",
    "        'r2_X1': [r2_X1],\n",
    "        'mse_X2': [mse_X2],\n",
    "        'rmse_X2': [rmse_X2],\n",
    "        'r2_X2': [r2_X2],\n",
    "        'mse_X3': [mse_X3],\n",
    "        'rmse_X3': [rmse_X3],\n",
    "        'r2_X3': [r2_X3],\n",
    "        'X1_cover_mean': [X1_cover_mean],\n",
    "        'X2_cover_mean': [X2_cover_mean],\n",
    "        'X3_cover_mean': [X3_cover_mean],\n",
    "    })\n",
    "\n",
    "    print(\"Returning result:\", result)\n",
    "    return result, cached_results  # 返回结果和缓存的 results\n",
    "\n",
    "\n",
    "# 示例：循环不同的噪声水平\n",
    "noise_levels = [1, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 150, 200]\n",
    "\n",
    "# noise_levels = [10, 50, 100, 150, 200]\n",
    "\n",
    "options = ['X1_only', 'X2_only', 'X3_only', 'X1_and_X2_and_X3', 'X1_and_X2', 'X1_and_X3', 'X2_and_X3', 'constant']\n",
    "\n",
    "for i in range(len(options)):\n",
    "    option = options[i]\n",
    "    results_list = []\n",
    "    cached_results = None  # 初始化缓存的 results\n",
    "\n",
    "    for level in noise_levels:\n",
    "        print(f\"Processing noise level: {level}\")\n",
    "        result, cached_results = Eva(level, cached_results, option=i, noise_type='uniform')  # 传入缓存的 results\n",
    "        print(f\"Appending result:\\n{result}\")\n",
    "        results_list.append(result)  #\n",
    "        print(f\"Current results_list length: {len(results_list)}\")\n",
    "\n",
    "    # 将结果转换为 DataFrame\n",
    "    results_df = pd.concat(results_list, ignore_index=True)  #\n",
    "\n",
    "    # outpath='/content/drive/MyDrive/Research/0-Xiayin_research/2_Conformal SHAP/result_x2.csv'\n",
    "    # results_df.to_csv(outpath)\n",
    "    results_df.to_csv(f'./results_uniform_nonlinear/results_multi_level_noise-{option}.csv')\n",
    "\n",
    "\n",
    "# results_list = []\n",
    "# cached_results = None  # 初始化缓存的 results\n",
    "#\n",
    "# for level in noise_levels:\n",
    "#     print(f\"Processing noise level: {level}\")\n",
    "#     result, cached_results = Eva(level, cached_results, option=2, noise_type='gaussian')  # 传入缓存的 results\n",
    "#     print(f\"Appending result:\\n{result}\")\n",
    "#     results_list.append(result)\n",
    "#     print(f\"Current results_list length: {len(results_list)}\")\n",
    "#\n",
    "#     # 将结果转换为 DataFrame\n",
    "# results_df = pd.concat(results_list, ignore_index=True)\n",
    "\n",
    "# outpath='/content/drive/MyDrive/Research/0-Xiayin_research/2_Conformal SHAP/result_x2.csv'\n",
    "# results_df.to_csv(outpath)\n",
    "# results_df.to_csv(f'./results_gaussian_noise_nonlinear/results_multi_level_noise-X1_and_X2.csv')\n",
    "# print(results_df)"
   ],
   "id": "94ec8933fdac4e6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results_uniform_noise",
   "id": "274ad2322e396f0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results_list",
   "id": "f13d82fa74741ee3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results_df",
   "id": "19ef7abd28c3e527",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7d13602ac7683958",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
